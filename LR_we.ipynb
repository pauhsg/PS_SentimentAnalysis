{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from proj2_helpers import *\n",
    "from get_embeddings_ML import *\n",
    "from ML_sklearn import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_EMB = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsize = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COOC_PATH = './Results/cooc.pkl'\n",
    "VOC_PATH = './Results/vocab.pkl'\n",
    "EMBEDDINGS_PATH = './Results/embeddings.npy'\n",
    "PP_POS_PATH = './Results/pp_pos_otpl_nd.txt'\n",
    "PP_NEG_PATH = './Results/pp_neg_otpl_nd.txt'\n",
    "PP_TEST_PATH = './Results/pp_test_otpl.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pickle files\n",
    "cooc_matrix = open_pickle_file(COOC_PATH)\n",
    "vocabulary = open_pickle_file(VOC_PATH)\n",
    "\n",
    "# load numpy files \n",
    "embeddings = np.load(EMBEDDINGS_PATH)\n",
    "\n",
    "# load the data files = list with each line being a tweet\n",
    "pos = open(PP_POS_PATH, \"r\").read().splitlines()\n",
    "neg = open(PP_NEG_PATH, \"r\").read().splitlines()\n",
    "test = open(PP_TEST_PATH, \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> process pos and neg datas to get X and y to perform ML\n",
      "> extracting mean of word vectors\n",
      "> extracting mean of word vectors\n",
      "> X and y informations:\n",
      "X shape: (173211, 20)\n",
      "y shape: (173211,)\n"
     ]
    }
   ],
   "source": [
    "full_df, X, y = process_train_ML(pos, neg, vocabulary, embeddings, DIM_EMB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Token_idx</th>\n",
       "      <th>Words_Vectors</th>\n",
       "      <th>Mean_Word_Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13184</th>\n",
       "      <td>1</td>\n",
       "      <td>aquaria flow wat</td>\n",
       "      <td>[1451, 965]</td>\n",
       "      <td>[[-0.9622639653642167, -0.11438350725839998, -...</td>\n",
       "      <td>[-0.15975510051974673, -0.023321416645571233, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146595</th>\n",
       "      <td>-1</td>\n",
       "      <td>fujifilm finepix digital camera casecrown comp...</td>\n",
       "      <td>[5536, 6739, 476, 454, 1589, 1212, 511, 18, 62...</td>\n",
       "      <td>[[0.7696199727151402, 1.0906601137983498, -1.2...</td>\n",
       "      <td>[-0.1809942545563328, 0.4230139861370421, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94968</th>\n",
       "      <td>-1</td>\n",
       "      <td>get work saturday predictable</td>\n",
       "      <td>[0, 28, 345, 11034]</td>\n",
       "      <td>[[0.005535928245646655, 0.1830141817699408, 0....</td>\n",
       "      <td>[-0.25992197730989675, 0.11858692398290718, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142364</th>\n",
       "      <td>-1</td>\n",
       "      <td>eco soccer ball match size orange band certify...</td>\n",
       "      <td>[3120, 1095, 448, 765, 368, 963, 603, 2768, 71...</td>\n",
       "      <td>[[1.3289314752180335, 2.8532879875338133, -1.7...</td>\n",
       "      <td>[0.03804013754615492, -0.08464376685349886, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105437</th>\n",
       "      <td>-1</td>\n",
       "      <td>polaroid digital camera casecrown compact pad ...</td>\n",
       "      <td>[4151, 476, 454, 1589, 1212, 511, 18, 625, 972...</td>\n",
       "      <td>[[0.08213692419147511, 0.8573249901651587, 0.7...</td>\n",
       "      <td>[-0.2836888479688993, 0.39782027537702097, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentiment                                              Tweet  \\\n",
       "13184           1                                   aquaria flow wat   \n",
       "146595         -1  fujifilm finepix digital camera casecrown comp...   \n",
       "94968          -1                      get work saturday predictable   \n",
       "142364         -1  eco soccer ball match size orange band certify...   \n",
       "105437         -1  polaroid digital camera casecrown compact pad ...   \n",
       "\n",
       "                                                Token_idx  \\\n",
       "13184                                         [1451, 965]   \n",
       "146595  [5536, 6739, 476, 454, 1589, 1212, 511, 18, 62...   \n",
       "94968                                 [0, 28, 345, 11034]   \n",
       "142364  [3120, 1095, 448, 765, 368, 963, 603, 2768, 71...   \n",
       "105437  [4151, 476, 454, 1589, 1212, 511, 18, 625, 972...   \n",
       "\n",
       "                                            Words_Vectors  \\\n",
       "13184   [[-0.9622639653642167, -0.11438350725839998, -...   \n",
       "146595  [[0.7696199727151402, 1.0906601137983498, -1.2...   \n",
       "94968   [[0.005535928245646655, 0.1830141817699408, 0....   \n",
       "142364  [[1.3289314752180335, 2.8532879875338133, -1.7...   \n",
       "105437  [[0.08213692419147511, 0.8573249901651587, 0.7...   \n",
       "\n",
       "                                         Mean_Word_Vector  \n",
       "13184   [-0.15975510051974673, -0.023321416645571233, ...  \n",
       "146595  [-0.1809942545563328, 0.4230139861370421, 0.03...  \n",
       "94968   [-0.25992197730989675, 0.11858692398290718, 0....  \n",
       "142364  [0.03804013754615492, -0.08464376685349886, -0...  \n",
       "105437  [-0.2836888479688993, 0.39782027537702097, 0.1...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check full_df\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> splitting datas into train and test sets\n",
      "> standardizing\n",
      "> performing PCA\n",
      "Train set: X shape:  (138568, 19) y shape: (138568,)\n",
      "Test set: X shape:  (34643, 19) y shape: (34643,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, scaler, pca = split_standardize_pca(X, y, testsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5876511849435673\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegression(C=1e-2, max_iter=100000, n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "compute_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> process test data to get X_test and perform ML\n",
      "> extracting mean of word vectors\n",
      "> X_test informations:\n",
      "X_test shape: (10000, 20)\n"
     ]
    }
   ],
   "source": [
    "df_test, testx = process_test_ML(test, vocabulary, embeddings, DIM_EMB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = std_pca_test(testx, scaler, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify length of test:  10000\n"
     ]
    }
   ],
   "source": [
    "create_submission(df_test, y_pred_test, './Submissions/LR_we.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
